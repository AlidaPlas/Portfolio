---
title: "Portfolio Computational Musicology 2022 - Alida Plas"
author: "About Sabrina Carpenter"
output:
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: flatly
    self_contained: false
---
```{r include = FALSE}
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(usethis)
library(compmus)
library(datasets)
library(patchwork)
library(ggdendro)
library(heatmaply)
library(tidymodels)
library(plotly)
library(protoclust)
```

### Dendogram

```{r}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

Sabrina_Carpenter <-
  get_playlist_audio_features("bnfcollection", "4qzoGolRadySzIJfoeh2Os") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

SabrinaCarpenter_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = Sabrina_Carpenter
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  prep(Sabrina_Carpenter %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")

Sabrina_dist <- dist(SabrinaCarpenter_juice, method = "euclidean")

Sabrina_dist %>% 
  hclust(method = "single") %>% 
  dendro_data() %>%
  ggdendrogram()
```


### Introduction Portfolio

The collection of music that I would like to learn more about are the songs of Sabrina Carpenter. I choose this artist, because I have been listening to her music for 7 years now. I grew up with her, but she also did and her music has changed a lot over time. Sabrina’s first single ‘Can’t Blame a Girl for Trying’ came out in March 2014 when she was 14 years old. She is now 22 and in the mean time she released four albums and many singles. 

So my comparison points will be the different albums of Sabrina Carpenter. Her first album, ‘Eyes Wide Open’, which talks about love and teenage problems, has a pop sound with a bit of folk. The production mainly consists of guitars, piano and drums. Her last album ‘Singular: Act II’, released in 2019, is a dance, pop and R&B record. In general, she discusses self-reflection and self-discovery. So both in style and theme there is already a difference.
What I would like to find out is how her music has changed over the years. Has anything stayed the same during that time and what has changed? You can hear a difference, but where exactly is it?

A song that is atypical is ‘Skinny Dipping’. It is one of her recent singles, which will be part of her new coming album. In this song she mainly talks and describes an imaginary world. She starts singing in the pre-chorus, but the narrative part is accompanied with an instrumental background. 

***

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/album/55huyEjfSVsk9nnmmKp5df?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

---

### Valence over time

```{r}
EWO <- get_playlist_audio_features("","2PUT9OaUA6eODR3et4CFXB") 
EVOL <- get_playlist_audio_features("","6wLxOjmHS2ojcXLlgSnfNB")
SAI <- get_playlist_audio_features("","3bEVrN4e4ZZT3abT0qvLTh")
SAII <- get_playlist_audio_features("","0ajsJz4w31SYpdGObMUZQ8")

Album <-
  bind_rows(
    EWO %>% mutate(category = "EWO"),
    EVOL %>% mutate(category = "EVOL"),
    SAI %>% mutate(category = "SAI"),
    SAII %>% mutate(category = "SAII")
  )

Album %>%
  ggplot(aes(x = category, y = valence)) +
  geom_boxplot()

```

***
When I listen to the various albums of Carpenter myself, I hear that her first album is clearly 'more cheerful' than her last. But what does Spotify say about this. The API called valence, describes the musical positiveness conveyed by a track.

The order of the albums is: 'Eyes Wide Open' (EWO), 'EVOLution' (EVOL), 'Singular Act I' (SAI) and 'Singular Act II' (SAII).

Sabrina's first album, which is also described as upbeat, has the highest maximum. Which therefore fits what you can hear.

Singular act I and II both belong to 1 project, but were released separately due to the difference in lyrical content. Act I is an album full of self-confidence, while Act II is filled with feelings and emotions. In the box plot you see that the average of the positiveness is much lower with Act I than the album in which many emotional things are also discussed. This is mainly because text is not included, but it is an interesting observation. Because with your ear, you would have judged it differently. The median of SAI and SAII are in the same place. The middle value of both albums is equal. Singular Act II also has a few outliers. 'Tell em' has a valence of 0.199, 'Exhale' 0.276 and 'Take Off All Your Cool' 0.809. I myself was surprised at the result of 'Take Off All Your Cool' and wonder what other people think of this API score from Spotify.

You also see that the box of EVOL and SAII barely overlap. This also means that the difference between the two is the greatest. The valence at SAII is higher on average. Evolution's tracks sound more sad, depressed and angry. SAII's tracks sound the most cheerful, cheerful and euphoric.

Over the years, the valence has been very varied.

---

### Comparing the outlier 'Take Off All Your Cool' with the mean of valence

```{r}
TakeOfAllYourCool <-
  get_tidy_audio_analysis("27B9H3cOefm9lWDfh9A0gj") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

GraphT <- TakeOfAllYourCool %>%
  mutate(pitches = map(pitches, compmus_normalise, "manhattan")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

RunAndHide <-
  get_tidy_audio_analysis("24fhYqs2KtWbHfY4Ngdf5U") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

GraphR <- RunAndHide %>%
  mutate(pitches = map(pitches, compmus_normalise, "manhattan")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

( GraphT | GraphR )

```

***
For this chromogram I wanted to use the outlier we found in the boxplot of 'Valence over time'. Apparently is 'Take Off All Your Cool' an atypical song of Sabrina Carpenter. I calculated the mean of valence and found out that her song 'Run and Hide' has exactly the same value of valence. 

On the left you see the chromogram of 'Take off All Your Cool' and on the right 'Run and Hide'. One thing that immediately stood out, is that 'Take Off All Your Cool looks' chaotic compared to 'Run and Hide'. The latter is more structured, whereas the other makes more use of different pitches.

---

### Oldest versus newest single

```{r}
CBaGfT <-
  get_tidy_audio_analysis("5K7fGxZQB0K5sPKhLe9e07") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

Graph1 <- compmus_long_distance(
  CBaGfT %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  CBaGfT %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "manhattan"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Can't Blame a Girl for Trying", y = "") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

CBaGfT <-
  get_tidy_audio_analysis("5K7fGxZQB0K5sPKhLe9e07") %>% 
  compmus_align(bars, segments) %>%                     
  select(bars) %>%                                      
  unnest(bars) %>%                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"             
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              
      )
  )

Graph2 <- CBaGfT %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

FastTimes <-
  get_tidy_audio_analysis("0oN3KzKOxYtyIuNiobf8Q4") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

graph3 <- compmus_long_distance(
  FastTimes %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  FastTimes %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "cosine"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Fast Times", y = "") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

FT <-
  get_tidy_audio_analysis("0oN3KzKOxYtyIuNiobf8Q4") %>% 
  compmus_align(bars, segments) %>%                     
  select(bars) %>%                                      
  unnest(bars) %>%                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"             
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              
      )
  )

Graph4 <- FT %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

(Graph1 | graph3) / (Graph2 | Graph4)
```

***
A few weeks ago, Carpenter released her latest single called 'Fast Times'. Compared to her first single, the style is completely different. The purpose of this page is therefore to compare her first single, which was released on March 14, 2014, 'Can't Blame a Girl for Trying', with her last single, which was released on February 18, 2022.
In the chromagram of Fast Times we can clearly see how the song is built and how certain parts come back. The first small block is the intro, this runs to about 10 seconds. Then the verse starts which is actually built on the intro, so it's light blue. It's very similar. In the 3 block, around 25 seconds, there is a modulation that you see again. Yet the first part is all very similar which makes it a big block. After that comes a block with a lot of yellow, this means that it is very different. Which is also true because this is where the chorus starts. Then follows the block of the verse. Followed by 2 times the chorus. A cross is created there, in other words the bridge. And then the chorus again.

The chromagram of ‘Can't Blame a Girl for Trying shows less structure’. Everything looks the same. So you can say that the latest single has more of a structure and structure with clear differences. 

If we compare timbre, instead of the pitches, we can see that there is a big change in 'Can't Blame a Girl for Trying'. Whereas in 'Fast Times' the timbre changes a little bit over the course of the song. 

### Tempo, Loudness and Duration

```{r}
EyesWideOpen <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "2PUT9OaUA6eODR3et4CFXB"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

EVOLution <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "6wLxOjmHS2ojcXLlgSnfNB"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

SingularI <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "3bEVrN4e4ZZT3abT0qvLTh"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

SingularII <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0ajsJz4w31SYpdGObMUZQ8"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

Sabrina <-
  EyesWideOpen %>%
  mutate(genre = "EyesWideOpen") %>%
  bind_rows(EVOLution %>% mutate(genre = "Evolution")) %>%
  bind_rows(SingularI %>% mutate(genre = "SingularI")) %>%
  bind_rows(SingularII %>% mutate(genre = "SingularII"))

Sabrina %>%
  mutate(
    sections =
      map(
        sections,                                    
        summarise_at,
        vars(tempo, loudness, duration),             
        list(section_mean = mean, section_sd = sd)   
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 3.2) +
  labs(
    title = "",
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***
The last time I compared the first and newest single of Carpenter. So now, I wanted to look at her albums again. Therefore I made a summary of other Spotify's lower-level track audio analysis, that I have not used before. 
In this graph, you can clearly see that the albums of Carpenter are close to each other, with some outliers. 'Eyes Wide Open' has for example a smaller mean tempo overall, whereas 'Singular Act II' uses different tempi.
However, 'Eyes Wide Open' has also the biggest outlier and scores 3,1 at SD tempo. The loudness of 'Singular Act II' is also the softest. And the song with the shortest duration is on 'Singular Act I'.
---

### Chordogram

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

SueMe <-
  get_tidy_audio_analysis("3WVhkjB7Y4xFruqoCAajBb") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

Graph5 <- SueMe %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "manhattan",  
    norm = "euclidean"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "Sue Me", x = "Time (s)", y = "")

Dontwantitback <-
  get_tidy_audio_analysis("2yqhHi9QfZ5INE13sS5Bva") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

Graph6 <- Dontwantitback %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "manhattan",  
    norm = "euclidean"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "Don't want it back", x = "Time (s)", y = "")

Pushing20 <-
  get_tidy_audio_analysis("1xMHC2XPuDyBWU1ULY7eMA") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

Graph7 <- Pushing20 %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "manhattan",  
    norm = "euclidean"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "Pushing 20", x = "Time (s)", y = "")

SmokeAndFire <-
  get_tidy_audio_analysis("67zT3NI4tTOj8GreXetF6s") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

Graph8 <- SmokeAndFire %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "manhattan",  
    norm = "euclidean"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(title = "Smoke and Fire", x = "Time (s)", y = "")

(Graph5 | Graph6) / (Graph7 | Graph8)
```

***
I have chosen random songs by Sabrina Carpenter for these chordograms. I put Spotify on shuffle and these were the first four that came up.
The order of release is: Smoke and Fire - Don't Want It Back - Sue me - Pushing 20. Smoke and Fire is a single and the others all belong to a different album.
'Sue Me' mainly uses Gb major and D# minor. The chords that are in the middle of the chordogram are hardly used in this song. The same goes for 'Don't Want It Back'.
At 'Pushing 20' you actually see 3 lines of dark blue. C# minor, E minor, C major and F minor. But with 'Smoke and Fire' you see a wider blue line. So it contains a lot of chords.
Overall, in all songs it's really clear which chords are used, except for 'Don't Want It Back'. 

### Histogram of tempi for different albums

```{r}
EWO <- get_playlist_audio_features("","2PUT9OaUA6eODR3et4CFXB") 
EVOL <- get_playlist_audio_features("","6wLxOjmHS2ojcXLlgSnfNB")
SAI <- get_playlist_audio_features("","3bEVrN4e4ZZT3abT0qvLTh")
SAII <- get_playlist_audio_features("","0ajsJz4w31SYpdGObMUZQ8")

Album <-
  bind_rows(
    EWO %>% mutate(category = "EWO"),
    EVOL %>% mutate(category = "EVOL"),
    SAI %>% mutate(category = "SAI"),
    SAII %>% mutate(category = "SAII")
  )

Album %>%
  ggplot(aes(x = tempo)) +
  geom_histogram(binwidth = 2) +
  facet_wrap(~category)
```

***

In this histogram you can see the different tempi of the different albums of Sabrina Carpenter. You can see in this figure that 'Singular Act II' uses different tempi, 'Act I' is also scattered but doesn't have songs with a really high BPM. At 'Evolution' the songs are kind of sorted into 3 groups. At 'Eyes Wide Open' the majority is mainly very low in BPM. Because of this histogram you can clearly see differences between the tempi of the albums.

### Tempogram of one outlier and an atypical song

```{r}
InMyBed <- get_tidy_audio_analysis("1FjD1jpm51dH5LzLvrDVPY")

GraphI <- InMyBed %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(title = "In My Bed", x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

SkinnyDipping <- get_tidy_audio_analysis("7u6HtmuMeuiVdwwFul5xHi")

GraphS <- SkinnyDipping %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(title = "Skinny Dipping", x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

(GraphI | GraphS)

```

***

I found out that the results of the two outliers of Singular Act II are different in the tempogram. They are both halved, as you can see in the tempogram of 'In My Bed'. It has a tempo of 218 BPM, in the tempogram its around 110 BPM. I don't really know where that 'error' comes from. When I listen to the song I hear 110 rather than 218. Especially because there is a slow clap in it. 

I made a second tempogram of a song that's in her upcoming album. I talked about it in the introduction, 'Skinny Dipping'. In this song she mainly talks and she starts singing in the pre-chorus. The beat on the background is continuous/regular, but the way she sings over this seams confusing to me. I tried to sing it while playing the beat on my guitar, but I couldn't do it correctly. In the tempogram there is not a straight line of stability. It seems that most activity is around 90 BPM. But it looks chaotic.

